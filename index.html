<!--
Author: W3layouts
Author URL: http://w3layouts.com
License: Creative Commons Attribution 3.0 Unported
License URL: http://creativecommons.org/licenses/by/3.0/
-->
<!DOCTYPE html>
<html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-55432648-1', 'auto');
  ga('send', 'pageview');
</script>	
<head>
<title>Neuro-robotic, developmental robotics researcher: J.
ZHONG</title>
<link href="css/style.css" rel='stylesheet' type='text/css' />
<link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="keywords" content="Splashy Bootstrap  Responsive web template,booklet, layout, bookblock, jquery plugin, Bootstrap Web Templates, Flat Web Templates, Andriod Compatible web template, 
Smartphone Compatible web template, free webdesigns for Nokia, Samsung, LG, SonyErricsson, Motorola web design" 
/>
<script type="application/x-javascript"> addEventListener("load", function() { setTimeout(hideURLbar, 0); }, false); function hideURLbar(){ window.scrollTo(0,1); } </script>
</script>

<script src="js/jquery-1.11.0.min.js"></script>
<script src="js/modernizr.custom.js"></script>
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10676781; 
var sc_invisible=1; 
var sc_security="238bae2f"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web statistics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="http://c.statcounter.com/10676781/0/238bae2f/1/"
alt="web statistics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
<!--webfonts-->
		<link href='http://fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,400italic,500,500italic,700|Raleway:400,100,200,300,500,600,700' rel='stylesheet' type='text/css'>
<!--//webfonts-->
</head>
<body>
	<div class="dummy">	
			<div id="bl-main" class="bl-main">
				<section>
					<div class="bl-box">
						<div class="eye-box">
							<img src="images/eye.png" alt="" />
							<h2 class="bl-icon bl-icon-about">About</h2>
						</div>
					</div>
					<div class="bl-content about">
						<div class="container">
							<h2>About Me</h2>
								<div class="inner-about">
									<script type="text/javascript">
<!--
var imlocation = "images/";
var currentdate = 0;
var image_number = 0;
function ImageArray (n) {
this.length = n;
for (var i =1; i <= n; i++) {
this[i] = ' '
}
}
image = new ImageArray(4)
image[1] = 'zhong2.jpg'
image[2] = 'zhong3.jpg'
image[3] = 'zhong4.jpg'
image[0] = 'zhong5.jpg'
var rand = 60/image.length
function randomimage() {
currentdate = new Date()
image_number = currentdate.getSeconds()
image_number = Math.floor(image_number/rand)
return(image[image_number])
}
document.write("<center><img src='" + imlocation + randomimage()+ "' width='400' ></center>");
//--></script>
									<h3>My name is Junpei 'Joni' Zhong, a junior researcher at Lab for Intelligent Dynamics and Representation, Waseda University, Tokyo. I'm also a visiting researcher at Plymouth University. My research is committed to build learning models for artificial cognitive systems. In most cases, such models are inspired by biologial systems.</h3>
									<div class="item_content">
								<!-- Introtext -->
									<div class="col-md-6 item_introtext">
										
	<p> <b>Education </b></p>									
<p> Dr.rer.nat. July 2010 - April 2015 </p>
<p> Department of Computer Science, Uni. of Hamburg, DE. </p>

<p> M.Phil.  Oct 2007 - Oct 2009 </p>
<p> Department of Electrical Engineering, The Hong Kong Polytechnic Uni., HK. </p>



<p> B.Eng Sep 2002 - Sep 2006 </p>
<p> Double degrees in Control Science and Computer Science, South China Uni. of Tech.,
CN. </p>


<p> </p>
<p> </p>

<p><b> Experience</b> </p>									
<p> Marie Curie Early Stage Researcher, University of Hamburg, 2010 - 2013
 </p>


<p>  Visiting Researcher, Computing and mathematics, Uni. of Plymouth, 2011 - 2013,
2016-present </p>

<p>  Research Fellow, School of Computer Science, Uni. of Hertfordshire, 2014 </p>

<p> Postdoc Researcher, Computing and mathematics, Uni. of Plymouth, 2015 </p>

<p> Junior Researcher (Fixed-term Assistant Professor), Lab for Intelligent
Dynamics and Representations, Waseda University, 2016 </P>



									</div>
									<div class="col-md-6 item_introtext list">
										<ul class="item-list">
											<li>Languages Skills:
<p> Cantonese
(Mother Language), English (Proficiency), Chinese (Proficiency),  German (Fair)</li>
											<li>My current research encompasses the following interrelated research themes:
<p>1. Computational neuroscience, particularly the visual system modelling, and its relation into the affordance learning in the sensorimotor system; 
<p>2. Bootstrap learning for visual perception on robotic systems;
<p>3. Psychology, philosophy and their contributions to developmental robotics.
Besides, my previous research also includes SLAM, and its biological-inspired solutions.</li>
											



<li>Service and other Professonal Activities:</li>
<p><b>Program Committee,</b>
 
<p>The International Conference on Artificial Neural Networks, Hamburg, DE.
<p><b>Local Chair,</b>

<p>Postgraduate Conference on Robotics and Development of Cognition (RobotDoC-
PhD), Lausanne, CH.

<p><b>Ad-hoc reviewer,</b>
<p>IET Control Theory and Applications
<p>International Conference on Artificial Neural Networks
<p>International Journal of Control, Automation and Systems
<p>Optics Communications
<p>Applied Mathematics and Computation

										</ul>	
									</div>
									
								</div>
							</div>
								<!--our-team-->
								<div class="team-section">
										
								<div class="copy-right">
						<p>Copyright &copy; 2015  J. Zhong All rights  Reserved | Template by &nbsp;<a href="http://w3layouts.com">W3Layouts</a></p>
<p><a href="mailto:zhong@junpei.eu">zhong@junpei.eu</a></p>

					</div>
						</div>
					</div>
			<span class="bl-icon bl-icon-close"><img src="images/close.png" alt="" /></span>
		</section>
		<section id="bl-work-section">
			<div class="bl-box">
				<div class="eye-box">
					<img src="images/service.png" alt="" />
					<h2 class="bl-icon bl-icon-works">Research</h2>
				</div>
			</div>
			<div class="bl-content works">
				<div class="container">
				<h2>research</h2>
				<div class="work">
					
						<ul id="bl-work-items">
							<li data-panel="panel-1"><a href="#"><img src="images/slam.PNG" /></a><h3>Multi-robot SLAM</h3></li>
							<li data-panel="panel-2"><a href="#"><img src="images/pam.PNG" /></a><h3>Feedback pathways in sensorimotor system</h3></li>
							<li data-panel="panel-3"><a href="#"><img src="images/kinect.jpg" /></a><h3>Neural learning for emotion recognition</h3></li>
							<li data-panel="panel-4"><a href="#"><img src="images/icub.jpg" /></a><h3>Language acquisition by embodiment</h3></li>
							<div class="clearfix"></div>
						</ul>
						<div class="copy-right one">
						<p>Copyright &copy; 2015 J. Zhong All rights  Reserved | Template by &nbsp;<a href="http://w3layouts.com">W3Layouts</a></p>
<p><a href="mailto:zhong@junpei.eu">zhong@junpei.eu</a></p>
					</div>
				</div>
			</div>
				<span class="bl-icon bl-icon-close"><img src="images/close.png" alt="" /></span>
			</section>
			<section>
				<div class="bl-box">
					<div class="eye-box">
						<img src="images/box.png" alt="" />
						<h2 class="bl-icon bl-icon-blog">publications</h2>
					</div>
				</div>
				<div class="bl-content serve">
					<div class="container">
						<h2>publications</h2>
						<p>THESIS
<p>Utilization
and Optimization for Particle
Filtering Multi-robot SLAM

<P>Supervisor: Dr.
Y.F. Fung, MPhil Thesis, Department of
Electrical Engineering, The Hong Kong Polytechnic University, Hong Kong<br />
<div style="text-align: right;"><a href="pubs/Master2009.pdf" target="_blank">&lt;PDF&gt;</a></div>

<p>Artificial Neural Network for Feedback Pathways for Sensorimotor Integration
<P>Supervisor: Prof.
S. Wermter, Doctoral Thesis, Department of
Computer Science, University of Hamburg, Germany<br />
<div style="text-align: right;"><a href="pubs/phd2015.pdf" target="_blank">&lt;PDF&gt;</a></div>
</td>
</tr>
</tbody>
</table>
<p style="text-align: right;"></p>
<p>JOURNALS
<p>Zhong, J.P., Fung Y.F. and Dai M.J. <i>Ant Colony
Optimization Assisted
Particle Filters</i>. International Journal of Control,
Automation, and
Systems. pp. 519-526, June, 8(3), 2010.</p>
<p style="text-align: right;"><a href="http://link.springer.com/article/10.1007%2Fs12555-010-0304-7" target="_blank">&lt;Link&gt;</a></p>
<p style="text-align: right;"><br />
</p>
<p>Zhong, J., and Fung, Y.F. <i>Case Study and Proofs of
Ant Colony
Optimisation Improved Particle Filter Algorithm</i>. IET Control
Theory and
Applications. pp. 689-697, 6(5), 2012.</p>
<p style="text-align: right;"><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&amp;arnumber=6179380" target="_blank">&lt;Link&gt;</a><a href="pubs/IET2012-acopf-case%20study.pdf" target="_blank">&lt;PDF&gt;</a></p>
<p style="text-align: right;"><br />
</p>
<p>Zhong, J., Weber, C. and Wermter, S. <i>A Predictive
Network Architecture
for a Robust and Smooth Robot Docking Behavior</i>. Paladyn.
Journal of
Behavioral Robotics.pp. 172–180,3(4), 2012b.</p>
<p>&nbsp;</p>
<p style="text-align: right;"><a href="http://link.springer.com/article/10.2478/s13230-013-0106-8" target="_blank">&lt;Link&gt;</a><a href="pubs/Paladyn2013-predictive-embodiment-preprint.pdf" target="_blank">&lt;PDF&gt;</a></p>
<p>Zhong, J., Cangelosi, A. and Wermter, S. <i>Towards a
self-organizing pre-symbolic neural model representing sensorimotor
primitives</i>
. Frontiers in Behavioral Neuroscience,  8:22, 2014</p>
<p style="text-align: right;"><a target="_blank" href="pubs/SI-presymbol2014.pdf">&lt;PDF&gt;</a>&nbsp;</p>
<p style="text-align: right;"><a href="pubs/Paladyn2013-predictive-embodiment-preprint.pdf" target="_blank"> </a></p>
<p style="text-align: right;"><br />
</p>
<p> J. Zhong, M. Peniak, J. Tani, T. Ogata, and A. Cangelosi. Sensorimotor
input as a language generalisation tool: A connectionist model for generation and generalisation of noun-verb combinations with sensorimotor inputs
(submitted). Autonomous Robots, 2016 </p>

<p>  X. Zhang, J. Zhang, and J. Zhong. Bio-mimetic perception-action integration toward intelligent behaviors for an autonomous robot: A view from hierarchical temporal memory (submitted). IEEE Transactions on Cognitive and Developmental Systems, 2016 </p>

<p>CONFERENCE PAPERS
<p>Zhong, J.P. and Fung, Y.F., <i>A Biological Inspired
Improvement Strategy
for Particle Filters</i>. Proceedings, IEEE 2009 International
Conference on
Industrial Technology (ICIT 09), Australia, pp. 1-6, 10-13 Feb 2009.</p>
<p style="text-align: right;"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4939539&amp;tag=1" target="_blank">&lt;LInk&gt;</a></p>
<p style="text-align: right;">&nbsp;<br />
</p>
<p>Zhong, J.P. and Fung,&nbsp;<span style="font-style: italic;">A Detailed Analysis
of the Ant Colony Optimization Enhanced Particle Filters</span>.Proceedings
of
the Internatonal Conference on Electric and Electronic (EEIC 2011),
LNEE 98,
pp. 641-648,&nbsp; Springer Heidelberg. Nanchang, China,
&nbsp;June 2011.</p>
<p style="text-align: right;"><a href="http://link.springer.com/chapter/10.1007/978-3-642-21765-4_79" target="_blank">&lt;Link&gt;</a><a href="pubs/EEIC2011_case_study.pdf">&lt;PDF&gt;</a>&nbsp;</p>
<p></p>
<p>Zhong, J.P., Weber, C. and Wermter S., <i>Robot
Trajectory Prediction and
Recognition based on a Computational Mirror Neurons Model</i>. In
Honkela, T.,
Duch, W., Girolami, M., Kaski, S., editors, Proceedings of the 21st
International Conference on Artificial Neural Networks (ICANN 2011),
Part II,
pp. 333-340, Espoo, Finland, June 2011.</p>
<p style="text-align: right;"><a href="http://dl.acm.org/citation.cfm?id=2029647" target="_blank">&lt;Link&gt;</a><a href="pubs/ICANN2011-rnnpb.pdf" target="_blank">&lt;PDF&gt;</a></p>
<p style="text-align: right;"><br />
</p>
<p>Zhong, J., Weber, C. and Wermter, S. <i>Restricted
Boltzmann Machine with
Transformation Units in a Mirror Neuron System Architecture</i>.
In Narioka,
K., Nagai, Y., Asada, M., Ishiguro, H., editors, Proceedings of the
IROS2011
Workshop on Cognitive Neuroscience Robotics (CNR), pp. 23-28, San
Francisco,
CA, USA, September 2011.</p>
<p style="text-align: right;"><a href="pubs/IROS2011-NR-rbmpb.pdf" target="_blank">&lt;PDF&gt;</a><a href="pubs/IROS2011-rbmpb-poster.pdf" target="_blank">&lt;Poster&gt;</a></p>
<p style="text-align: right;"><br />
</p>
<p>Zhong, J., Weber, C. and Wermter, S. <i>Learning
Features and
Transformations with a Predictive Horizontal Product Model</i>.
Proceedings of
Sixteenth International Conference on Cognitive and Neural Systems,
ICCNS 2012,
Boston, USA, 2012.</p>
<p style="text-align: right;"><a href="pubs/ICCNS2012-HP-RNN-abs.pdf" target="_blank">&lt;Abstract&gt;</a><a href="#" target="_blank">&lt;Poster&gt;</a></p>
<p style="text-align: right;"><br />
</p>
<p>Zhong, J., Weber, C., and Wermter, S. <i>Learning
Features and Predictive
Transformation Encoding Based on a Horizontal Product Model</i>.
In Villa,
A.E.P., et al., editors, Proceedings of the 22nd International
Conference on
Artificial Neural Networks (ICANN 2012), Part I, LNCS 7552, pp.
539-546,
Springer Heidelberg. Lausanne, CH, September 2012.</p>
<p style="text-align: right;"><a href="http://dl.acm.org/citation.cfm?id=2407016" target="_blank">&lt;Link&gt;</a><a href="pubs/ICANN2012-HP-RNN.pdf" target="_blank">&lt;PDF&gt;</a></p>
<p>Zhong, J. and Canamero, L. <i>From Continuous Affective Space to Continuous Expression Space: Non-verbal Behaviour Recognition and Generation (Accepted)</i>.
The Fourth Joint IEEE International Conference on Development and Learning and on Epigenetic Robotics (ICDL-EpiRob 2014).
</p><p style="text-align: right;"><a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982957&tag=1" target="_blank">&lt;Link&gt;</a><a href="pubs/ICDL2014-expression-space-rnnpb.pdf" target="_blank">&lt;PDF&gt;</a></p>
<p> Zhong, J., Novianto,R., Dai, M., Zhang, X., and Cangelosi, A.  <i> A hierarchical
emotion regulated sensorimotor model: Case studies </i>.
The 5th
International Conference on Data-Driven Control and Learning Systems. 2016
</p><p style="text-align: right;"><a href="#" target="_blank">&lt;Link&gt;</a><a href="pubs/CCDC_en_emotion_modelling2016_v12.pdf" target="_blank">&lt;PDF&gt;</a></p>
				
					<div class="copy-right one">
						<p>Copyright &copy; 2015 J.Zhong All rights  Reserved  | Template by &nbsp;<a href="http://w3layouts.com">W3Layouts</a></p>
<p><a href="mailto:zhong@junpei.eu">zhong@junpei.eu</a></p>
					</div>
	    		</div>
	    	</div>
		<span class="bl-icon bl-icon-close"><img src="images/close.png" alt="" /></span>
	</section>
	<section>
		<div class="bl-box">
			<div class="eye-box">
				<img src="images/mail.png" alt="" />
				<h2 class="bl-icon bl-icon-contact">Links</h2>
			</div>
		</div>
		<div class="bl-content">
		<div class="contact_top">
			 		<div class="container">
			 			<h2>Links</h2>
			 			
			 				
							  
					        	<div class="company_ad">
							     		<h3>Collaborators</h3>

							     		
		<p> <span><a href="http://homepages.herts.ac.uk/~comqlc/" target="_new">Dr. Lola Cañamero (Adaptive Systems, University of Hertfordshire)</a></span>
	  <p> <span><a href="http://www.tech.plym.ac.uk/soc/staff/angelo/" target="_new">Prof. Angelo Cangelosi (CRNS, University of Plymouth)</a></span>
<p> <span><a href="http://www.ee.polyu.edu.hk/en/people_detail.php?name=Yu-faiFUNG&cid=2&id=10" target="_new">Dr. Yu-fai Fung (EE, The Hong Kong Polytechnic University)</a></span>	
 <p> <span><a href="http://www.ronynovianto.com/" target="_new">  Dr. Rony Novianto (University of Technology Sydney)</a></span>
	<p> <span><a href="http://www.petersincak.com/" target="_new">  Prof. Peter Sinčák (CIT, TU Kosice)</a></span>
<p> <span><a href="http://neurorobot.kaist.ac.kr/tani.htm" target="_new">Prof. Jun Tani (EE, KAIST)</a></span>
<p> <span><a href="https://www2.informatik.uni-hamburg.de/~wermter/" target="_new">Prof. Dr. Stefan Wermter (WTM, University of Hamburg)</a></span>
<p> <span><a href="http://neuron.tuke.sk/maria.vircik/" target="_new">Dr. Mária Virčíková (CIT, TU Kosice)</a></span>
<p> <span><a href="http://zhangxz.weebly.com/" target="_new"> Dr. Xinzheng Zhang (Jinan University)</a></span>
    						<address>
			      							
									 	 	
							   			</address>
							   		</div>
							   		<div class="store">
							   			
							   			<div class="clearfix"> </div>  
							   		</div>
						    </div>				
							</div>	
						</div>
					</div>
					<div class="copy-right">
						<p>Copyright &copy; 2015  All rights  Reserved | Template by &nbsp;<a href="http://w3layouts.com">W3Layouts</a></p>
<p><a href="mailto:zhong@junpei.eu">zhong@junpei.eu</a></p>

							   				
					</div>
					</div>
					
					<span class="bl-icon bl-icon-close"><img src="images/close.png" alt="" /></span>
				</section>
				<!-- Panel items for the works -->
				<div class="bl-panel-items" id="bl-panel-work-items">
					<div data-panel="panel-1">
						<div>
							<img src="images/slam.PNG" />
							<h3>Bio-inspired Particle Filter and its SLAM application </h3>
							<p>The utilization of multi-robot systems has a major advantage when comparing to single robot systems, for example, with multiple robots working together, it has the potential to accomplish a task faster than a single robot. However, when a team of robots is sharing the same worksite, the Simultaneously Localization and Mapping (SLAM) problem becomes much more difficult to resolve because a huge amount of information is needed to be processed as well as analyzed. But on the other hand, multi-robot SLAM can be more efficient if robots can exchange and share information regarding their sensed data properly. In the SLAM problem, especially for Autonomous Underwater Vehicle (AUV) and Unmanned Aerial Vehicle (UAV), it is necessary to include non-linear and non-Gaussian parameters, for which the traditional Kalman Filter (KF) cannot yield ideal solution. In applications involving non-linear and non-Gaussian parameters, Particle Filters (PF), which are based on the concept of Monte Carlo simulation, are more suitable estimation techniques. However, in problems involving multiple dimensions, such as the multi-robot SLAM problem, when a huge number of particles are being used, two problems, namely particle impoverishment and sample size dependency, will occur during the particle updating stage and these problems will become more severe. The problems will reduce the accuracy of the estimation results and resampling algorithms, such as Sequential Importance Sampling, Stratified Resampling and Systematic Resampling are used to alleviate these two problems. </p>

<p>In my master thesis, a novel PF algorithm for tackling the particle impoverishment and sample size dependency problems is being studied and its application in a multi-robot system is examined. In this algorithm, Ant Colony Optimization (ACO) is incorporated into the generic particle filter in order to drive the proposal distribution to approximate the optimal solution. Mathematical proof and results obtained from a single variable estimation problem as well as from the robot localization problem show that, after the ACO optimization, better proposal distribution and more accurate estimation results can be obtained. In order to evaluate the performance of the ACO improved PF (PFACO) when applied to non-linear and non-Gaussian problems, such as the localization and SLAM problem, studies were conducted and utilization of PFACO algorithm for multi-robot systems was introduced. In a multi-robot environment, when two robots encounter, the same information on the same estimation problem represented by the two sets of particles will be re-evaluated based on information conveyed by particles from different sets. The particles are then merged into a single set and in such cases, parallel computing can be applied in order to reduce the processing time. By software simulation, our results are better than those from traditional approaches both in estimation error and execution time. </p>
						</div>
					</div>
					<div data-panel="panel-2">
						<div>
							<img src="images/pam.PNG" />
							<h3>Artificial Neural Models for Feedback
Pathways for Sensorimotor
Integration
</h3>
							<p>The brain comprises hierarchical modules on various physiological levels. Neural
feedback signals (including lateral and top-down connections) modulate the neural
activities via inhibitory or excitatory connections within/between these levels.
They have predictive and filtering functions on the neuronal population coding of
the bottom-up sensory-driven signals in the perception-action system.
<p>In this thesis, we propose that the predictive role of the feedback pathways at most
levels of action and perception can be modelled by the recurrent connections in
different artificial cognitive platforms (simulation and humanoid robots). This will
be examined by three recurrent neural network models. Furthermore, the three
models and experiments with them show that the recurrent neural networks are
able to model feedback pathways and to exhibit the feedback-related sensorimotor
predictive functions. This work was sponsored by <a href="http://www.robotdoc.org target="_blank">EU Marie Curie RobotDoc project</a>
<h3>Part I:</h3>
<p>In the first model, inspired by the study of neurobiology, we emphasize that the
feedback connections facilitate a predictive mechanism to compensate for the neural delay in the two streams (ventral and dorsal) of the visual system. We model
this with a novel recurrent network with a horizontal product. In the simulation, the recurrent connections give rise to the fast- and slow-changing neural
activations in the dorsal- and ventral-like hidden layer. Particularly the recurrent connections build a feedback channel to predict the upcoming neural activity
in the dorsal-like hidden layer, while another feedback channel maintains stable
neural encoding in the ventral-like hidden layer.
<img src="images/visual-streams.png" alt="Two Visual Streams">
<p>Publication:
Zhong, Junpei, Cornelius Weber, and Stefan Wermter. "Learning features and predictive transformation encoding based on a horizontal product model." Artificial Neural Networks and Machine Learning–ICANN 2012. Springer Berlin Heidelberg, 2012. 539-546.
<a href="codes/Horizontal_Product_RNN.zip">[Code]</a> <a href=pubs/ICANN2012-HP-RNN.pdf target="_blank">[Paper]</a></p>
<h3>Part II:</h3>
<p>In the second part of the thesis, a sensorimotor integration model with visual
prediction is implemented, whose visual perception part is considered to be the
dorsal stream representation of the first model. This further augments the visual
prediction with its role of guiding motor action. Together with the action module
which adopts a continuous reinforcement learning algorithm, this model allows a
smooth and faster docking behaviour for a humanoid robot.
<p>Publication:
Zhong, Junpei, Cornelius Weber, and Stefan Wermter. "A predictive network architecture for a robust and smooth robot docking behavior." Paladyn, Journal of Behavioral Robotics 3.4 (2012): 172-180. <a href="pubs/Paladyn2013-predictive-embodiment-preprint.pdf" target="_blank">[Link]</a><a href="codes/ContinuousActorCritic_2d_v2_commented.py" target="_blank">[Code (Continuous Actor Critic)]</a><p>
<iframe width="420" height="315" src="https://www.youtube.com/embed/uf2UFMqtw_M?rel=0" frameborder="0" allowfullscreen align="right"></iframe>
<h3>Part III:</h3>
<p>In the third experiment, we propose that the source of the feedback pathway could
be the high-level cognitive processes, such as pre-symbolic representations. Furthermore, the emergence of these cognitive processes and feedback-related sensorimotor functions are not independent processes but they integrate and assist each
other in a hierarchical way. Therefore, we augment the first horizontal product model with additional units, called parametric bias (PB) units, as a pre-symbolic
representation. In the robot experiments, we show that during the learning process of observing sensorimotor primitives, the pre-symbolic representation is self-
organized in the parametric units; during prediction, these representational units
act as a prior expectation which guides the robot to recognize and to expect
various pre-learned sensorimotor primitives.
<p>Publication:
Zhong, Junpei, Angelo Cangelosi, and Stefan Wermter. "Toward a self-organizing pre-symbolic neural model representing sensorimotor primitives." Frontiers in behavioral neuroscience 8 (2014). 
<a href="pubs/SI-presymbol2014.pdf" target="_blank">[Link]</a> <a href="codes/rnnpb-xy-sim-v2.8-work.py">[Code]</a></p>
<p>These three experiments demonstrate that implementation of the feedback pathways with recurrent connections can realize predictive sensorimotor functions. The
emergence of these feedback pathways also accounts for the pre-symbolic representation in cognitive systems. Furthermore, we claim that the recurrent connections
can be one of possible neural structures to build up the feedback pathways on the
sensorimotor integration in artificial cognitive systems.
</p>
						</div>
					</div>
					<div data-panel="panel-3">
						<div>
							<img src="images/kinect.jpg" />
							<h3>Neural learning for emotion recognition</h3>
							<p>In this work, a variant version of recurrent neural network is adopted to accomplish several tasks in non-verbal expression in emotions. This work was sponsored by <a href="http://www.aliz-e.org target="_blank">EU ALIZ-E project</a>.

<h2>Part I</h2>
<p>Based on Recurrent Neural Network with Parametric Bias Units, we trained with a selection of the data on expressive human movement collected using an inertial motion capture system in the first year and analyzed subsequently. We discovered that the RNNPB has additional PB variables that act as bifurcation parameters for the non-linear dynamics. Therefore, the PB units constitute a small-dimensional space to reduce features and represent slow-changing profiles (such as emotion) of the features of body movements. Furthermore, in agreement with of our above-mentioned study on analysis of human movement and with the work presented in the previous subsection, this behavioral expression space should not be restricted to the basic emotions but should also be continuous. </p>

<img src="images/rnnpb-emotions.PNG" alt="RNNPB trained with emotions">

Publication
Zhong, Junpei, and Lola Canamero. "From continuous affective space to continuous expression space: Non-verbal behaviour recognition and generation." Development and Learning and Epigenetic Robotics (ICDL-Epirob), 2014 Joint IEEE International Conferences on. IEEE, 2014.
<a href="pubs/ICDL2014-expression-space-rnnpb.pdf" target="_blank">[Link]</a>

<h2>Part II</h2>

<p>
With kinect input and coordinate mapping, in the second part of we successfully used RNNPB to identify personalised emotion with their non-verbal bahaviours. In this way, our lab colleagues brought together affect recognition, expression, and the internal parameters of the emotion model into the embodied “cognitive architecture” of the NAO robot to generate a child behaviour with various emotion expressions, since in this case affective behavioral expression and recognition are directly linked to the affective space modeling the (continuous) internal affective states of the robot and their dynamics. </p>

<p>Publication
Zhong, Junpei, and Lola Canamero. "A Personalised Emotion Recognition Learning Method for Assistive Humanoid Robot Systems" (In preparation). IEEE Transaction on Affective Computing. </p>

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/JusCuKvHg44?rel=0" frameborder="0" allowfullscreen align="center"></iframe>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/vT4DtVXMlR8?rel=0" frameborder="0" allowfullscreen align="center"></iframe>

<p>Introduction of the final product of ALIZ-E project: (Credit www.aliz-e.org)</p>

<iframe src="https://player.vimeo.com/video/111655200" width="500" height="281" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen align="center"></iframe>
						</div>
					</div>
					<div data-panel="panel-4">
						<div>
							<img src="images/icub.jpg" />
							<h3>Modelling Language Acquisition by Embodied Sensorimotor Integration</h3>
From the perspective of "synthetic neural modelling", the robot offers a natural way to model the embodied construals of nouns and verbs during the acquisition of the complete sentence.  Therefore developing a system that demonstrates some level of cognitive ability can lead to a better understanding of the neural machinery that leads to cognitive function.							

<p>During the second year of age, infants start to associate the names with the visual information that appears in the receptive field. Particularly with dynamic scenes (e.g., a man lifting a ball), with the guidance of visual attention, infants could construe the scenes flexibly, noticing the consistent action (e.g., lifting) and the consistent object (e.g., the ball).  Gradually their construals of the scenes were influenced by the words from the auditorial inputs (e.g. from their parents) so that they learn how to use grammatical form of a novel word used to describe them (verb or noun), and successfully mapped novel verbs to event categories (e.g., lifting actions) and novel nouns to object categories (e.g., balls). Moreover, infants’ representations were sufficiently abstract to permit them to extend novel verbs and nouns appropriately beyond the precise scenes on which they had been taught. </p>



<p>In the context of POETICON project, we conducted the robotic experiment by taking direct inspiration from this child psychology studies of verbs and nouns learning. We explore how this embodied interaction supports the learning of noval nouns and verbs. The iCub robot learns the novel object and a particular motor action with the guidance of instructor. The robot was allowed to learn part of the combination of the verbs and nouns (as shown in the table). However, the experimental result showed that the MTRNN network based neural learning allowed the robot to acquiare generalisation ability, which means that the robot is able to react with novel combinations that it has not learnt before. Further analysis also  impled that the nouns and the verbs are emerged as two independent activations in the internal neurodynamics which spreads in both the spatial and temporal domains. The resulting model qualitatively captures the infant data and makes interesting predictions that are currently being explored with new child experiments. 	</p>	
<p> Technically, in this project, I also participated the debugging and testing of <a href="http://aquila.sourceforge.net/" target="_blank">Aquila Software (Cognitive Robotics Architecture).</a> 
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#bbb;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#bbb;color:#594F4F;background-color:#E0FFEB;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#bbb;color:#493F3F;background-color:#9DE0AD;}
.tg .tg-yw4l{vertical-align:top}
</style>
<table class="tg">
  <tr>
    <th class="tg-yw4l">Training Set</th>
    <th class="tg-yw4l">Test Set</th>
  </tr>
  <tr>
    <td class="tg-yw4l">Lift the car</td>
    <td class="tg-yw4l">Lift the ball</td>
  </tr>
  <tr>
    <td class="tg-yw4l">Pull the tractor</td>
    <td class="tg-yw4l">Touch the car</td>
  </tr>
  <tr>
    <td class="tg-yw4l">Lift the ball</td>
    <td class="tg-yw4l">Pull the tractor</td>
  </tr>
</table>
	
Publication:

J. Zhong, M. Peniak, J. Tani, A. Cangelosi. Language as an Inference Tool for Cognitive Systems: A Connectionst Model for Generation and Generalisation of Sensorimotor Sequences by Language Aquisition (In Preparation). Autonomous Robots. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/1nm8srM8088?rel=0" frameborder="0" allowfullscreen align="center"></iframe>
Video Credit: Martin Peniak
</div>
					</div>
					<nav>
						<span class="bl-next-work">&gt; Next Project</span>
						<span class="bl-icon bl-icon-close"><img src="images/close.png" alt="" /></span>
					</nav>
				</div>
			</div>
		</div><!-- /container -->

		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
		<script src="js/boxlayout.js"></script>
		<script>
			$(function() {
				Boxlayout.init();
			});
		</script>
<!--start-copyright-->
   		<div class="copy-right">
   			<div class="container">
				<p>Copyright &copy; 2015  All rights  Reserved | Template by &nbsp;<a href="http://w3layouts.com">W3Layouts</a></p>
<p><a href="mailto:zhong@junpei.eu">zhong@junpei.eu</a></p>
		</div>
	</div>
	<!--//end-copyright-->
		 		
</body>
</html>
